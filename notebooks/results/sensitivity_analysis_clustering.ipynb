{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "api = wandb.Api(timeout=19)\n",
    "sweep = api.sweep('carla-pedestrians/sensitivity/sweeps/j7yihb85')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pedestrians_scenarios.karma.pose.skeleton import CARLA_SKELETON\n",
    "import pandas as pd\n",
    "\n",
    "columns = pd.MultiIndex.from_tuples([('missing_joint_probabilities', k) for k in CARLA_SKELETON.__members__.keys()] + [('F1Score', 'summary'), ('F1Score', 'max')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('sensitivity_analysis.csv'):\n",
    "    rows = []\n",
    "\n",
    "    for run in sweep.runs:\n",
    "        try:\n",
    "            row = list(run.config['missing_joint_probabilities']) + [run.summary['hp/F1Score'], run.history()['hp/F1Score'].max()]\n",
    "            rows.append(row)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    df.to_csv('sensitivity_analysis.csv')\n",
    "else:\n",
    "    df = pd.read_csv('sensitivity_analysis.csv', skiprows=2, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "joints = df.values[:, :-2]\n",
    "f1score = df.values[:, -2:].max(axis=1).reshape(-1, 1)\n",
    "\n",
    "X = np.concatenate((joints, f1score), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "params = {\n",
    "    \"quantile\": 0.3,\n",
    "    \"eps\": 0.3,\n",
    "    \"damping\": 0.9,\n",
    "    \"preference\": -200,\n",
    "    \"n_neighbors\": 3,\n",
    "    \"n_clusters\": 3,\n",
    "    \"min_samples\": 7,\n",
    "    \"xi\": 0.05,\n",
    "    \"min_cluster_size\": 0.1,\n",
    "}\n",
    "\n",
    "# estimate bandwidth for mean shift\n",
    "bandwidth = cluster.estimate_bandwidth(X, quantile=params[\"quantile\"])\n",
    "\n",
    "# connectivity matrix for structured Ward\n",
    "connectivity = kneighbors_graph(\n",
    "    X, n_neighbors=params[\"n_neighbors\"], include_self=False\n",
    ")\n",
    "# make connectivity symmetric\n",
    "connectivity = 0.5 * (connectivity + connectivity.T)\n",
    "\n",
    "# ============\n",
    "# Create cluster objects\n",
    "# ============\n",
    "ms = cluster.MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "two_means = cluster.MiniBatchKMeans(n_clusters=params[\"n_clusters\"])\n",
    "ward = cluster.AgglomerativeClustering(\n",
    "    n_clusters=params[\"n_clusters\"], linkage=\"ward\", connectivity=connectivity\n",
    ")\n",
    "spectral = cluster.SpectralClustering(\n",
    "    n_clusters=params[\"n_clusters\"],\n",
    "    eigen_solver=\"arpack\",\n",
    "    affinity=\"nearest_neighbors\",\n",
    ")\n",
    "dbscan = cluster.DBSCAN(eps=params[\"eps\"])\n",
    "optics = cluster.OPTICS(\n",
    "    min_samples=params[\"min_samples\"],\n",
    "    xi=params[\"xi\"],\n",
    "    min_cluster_size=params[\"min_cluster_size\"],\n",
    ")\n",
    "affinity_propagation = cluster.AffinityPropagation(\n",
    "    damping=params[\"damping\"], preference=params[\"preference\"], random_state=0\n",
    ")\n",
    "average_linkage = cluster.AgglomerativeClustering(\n",
    "    linkage=\"average\",\n",
    "    affinity=\"cityblock\",\n",
    "    n_clusters=params[\"n_clusters\"],\n",
    "    connectivity=connectivity,\n",
    ")\n",
    "birch = cluster.Birch(n_clusters=params[\"n_clusters\"])\n",
    "gmm = mixture.GaussianMixture(\n",
    "    n_components=params[\"n_clusters\"], covariance_type=\"full\"\n",
    ")\n",
    "\n",
    "clustering_algorithms = (\n",
    "    (\"MiniBatch\\nKMeans\", two_means),\n",
    "    (\"Affinity\\nPropagation\", affinity_propagation),\n",
    "    (\"MeanShift\", ms),\n",
    "    (\"Spectral\\nClustering\", spectral),\n",
    "    (\"Ward\", ward),\n",
    "    (\"Agglomerative\\nClustering\", average_linkage),\n",
    "    (\"DBSCAN\", dbscan),\n",
    "    (\"OPTICS\", optics),\n",
    "    (\"BIRCH\", birch),\n",
    "    (\"Gaussian\\nMixture\", gmm),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "from itertools import cycle, islice\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "\n",
    "num_joints = len(joints[0])\n",
    "sorted_f1score = np.argsort(f1score, axis=0)[:,0]\n",
    "sorted_joints = np.argsort((1 - joints).sum(axis=0), axis=0)\n",
    "joint_names = np.array(list(CARLA_SKELETON.__members__.keys()))[sorted_joints]\n",
    "\n",
    "bar_width = 20\n",
    "identification_width = 2\n",
    "\n",
    "sorted_joints = np.concatenate((sorted_joints, np.arange(num_joints, num_joints + identification_width)))\n",
    "\n",
    "plt.figure(figsize=(10, 70))\n",
    "plt.subplots_adjust(\n",
    "    left=0.02, right=0.98, bottom=0.001, top=0.95, wspace=0.05, hspace=0.5\n",
    ")\n",
    "\n",
    "for plot_num, (name, algorithm) in enumerate(clustering_algorithms):\n",
    "    t0 = time.time()\n",
    "\n",
    "    # catch warnings related to kneighbors_graph\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\n",
    "            \"ignore\",\n",
    "            message=\"the number of connected components of the \"\n",
    "            + \"connectivity matrix is [0-9]{1,2}\"\n",
    "            + \" > 1. Completing it to avoid stopping the tree early.\",\n",
    "            category=UserWarning,\n",
    "        )\n",
    "        warnings.filterwarnings(\n",
    "            \"ignore\",\n",
    "            message=\"Graph is not fully connected, spectral embedding\"\n",
    "            + \" may not work as expected.\",\n",
    "            category=UserWarning,\n",
    "        )\n",
    "        algorithm.fit(X)\n",
    "\n",
    "    t1 = time.time()\n",
    "    if hasattr(algorithm, \"labels_\"):\n",
    "        labels = algorithm.labels_.astype(int)\n",
    "    else:\n",
    "        labels = algorithm.predict(X)\n",
    "\n",
    "    colors = np.array(\n",
    "        list(\n",
    "            islice(\n",
    "                cycle(\n",
    "                    [\n",
    "                        matplotlib.colors.to_rgb(\"#377eb8\"),\n",
    "                        matplotlib.colors.to_rgb(\"#ff7f00\"),\n",
    "                        matplotlib.colors.to_rgb(\"#4daf4a\"),\n",
    "                        matplotlib.colors.to_rgb(\"#f781bf\"),\n",
    "                        matplotlib.colors.to_rgb(\"#a65628\"),\n",
    "                        matplotlib.colors.to_rgb(\"#984ea3\"),\n",
    "                        matplotlib.colors.to_rgb(\"#999999\"),\n",
    "                        matplotlib.colors.to_rgb(\"#e41a1c\"),\n",
    "                        matplotlib.colors.to_rgb(\"#dede00\"),\n",
    "                    ]\n",
    "                ),\n",
    "                int(max(labels) + 1),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    # add black color for outliers (if any)\n",
    "    if len(colors):\n",
    "        colors = np.vstack((colors, [matplotlib.colors.to_rgb(\"#000000\")]))\n",
    "    else:\n",
    "        colors = np.array([matplotlib.colors.to_rgb(\"#000000\")])\n",
    "\n",
    "    img_colors = np.array([((*colors[labels[i]],),) for i in range(len(joints))])\n",
    "\n",
    "    img = np.where(\n",
    "        np.expand_dims(np.hstack((\n",
    "            (joints == 0),\n",
    "            ((True, ) * identification_width, ) * len(joints)\n",
    "        )), 2),\n",
    "        img_colors.repeat(num_joints + identification_width, axis=1),\n",
    "        np.ones((len(joints), num_joints + identification_width, 3)),\n",
    "    ).astype(np.float32)\n",
    "\n",
    "    img_sorted = img[sorted_f1score][:,sorted_joints]\n",
    "    img_sorted = img_sorted.repeat(bar_width, axis=1)\n",
    "    img_sorted = img_sorted.transpose(1, 0, 2)\n",
    "\n",
    "    plt.subplot(10, 1, plot_num+1)\n",
    "    plt.title(name, size=10)\n",
    "    plt.imshow(img_sorted, interpolation=\"none\")\n",
    "    plt.yticks(np.arange(bar_width/2, num_joints * bar_width + bar_width/2, bar_width), joint_names)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bc6412d3a16fac449111427037f95615ac4f9eb0e21171480bd5fd4cd4869803"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('video2carla')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
