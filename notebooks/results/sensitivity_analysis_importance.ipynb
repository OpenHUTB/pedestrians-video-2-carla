{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "api = wandb.Api(timeout=19)\n",
    "sweep = api.sweep('carla-pedestrians/sensitivity/sweeps/j7yihb85')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pedestrians_scenarios.karma.pose.skeleton import CARLA_SKELETON\n",
    "import pandas as pd\n",
    "\n",
    "columns = pd.MultiIndex.from_tuples([('missing_joint_probabilities', k) for k in CARLA_SKELETON.__members__.keys()] + [('F1Score', 'summary'), ('F1Score', 'max')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('sensitivity_analysis.csv'):\n",
    "    rows = []\n",
    "\n",
    "    for run in sweep.runs:\n",
    "        try:\n",
    "            row = list(run.config['missing_joint_probabilities']) + [run.summary['hp/F1Score'], run.history()['hp/F1Score'].max()]\n",
    "            rows.append(row)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    df.to_csv('sensitivity_analysis.csv')\n",
    "else:\n",
    "    df = pd.read_csv('sensitivity_analysis.csv', skiprows=2, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [item[1] for item in df.columns.values[:26]]\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :26]\n",
    "y = df.iloc[:, 26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree for feature importance on a regression problem\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "# X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
    "# define the model\n",
    "model = DecisionTreeRegressor()\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "# summarize feature importance\n",
    "# for i,v in enumerate(importance):\n",
    "# \tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "# feature_importance = pd.DataFrame({'feature': a, 'importance': model.feature_importances_}).sort_values('importance', ascending=False)\n",
    "# plot feature importance\n",
    "# feature_importance.head(2)\n",
    "# pyplot.bar([x for x in range(len(importance))], importance)\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({'feature': a, 'importance': model.feature_importances_}).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance.plot.barh(x='feature', y='importance', figsize=(20, 10), legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
    "model=LinearRegression()\n",
    "\n",
    "model.fit(X,y)\n",
    "# importance=model.coef_\n",
    "# importance=np.sort(importance)\n",
    "#plotting the features and their score in ascending order\n",
    "feature_importance_lr = pd.DataFrame({'feature': a, 'importance': model.coef_}).sort_values('importance', ascending=False)\n",
    "\n",
    "feature_importance_lr.plot.barh(x='feature', y='importance', figsize=(20, 10), legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "joints = df.values[:, :-2]\n",
    "f1score = df.values[:, -2:].max(axis=1).reshape(-1, 1)\n",
    "\n",
    "X = np.concatenate((joints, f1score), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "params = {\n",
    "    \"quantile\": 0.3,\n",
    "    \"eps\": 0.3,\n",
    "    \"damping\": 0.9,\n",
    "    \"preference\": -200,\n",
    "    \"n_neighbors\": 3,\n",
    "    \"n_clusters\": 3,\n",
    "    \"min_samples\": 7,\n",
    "    \"xi\": 0.05,\n",
    "    \"min_cluster_size\": 0.1,\n",
    "}\n",
    "\n",
    "# estimate bandwidth for mean shift\n",
    "bandwidth = cluster.estimate_bandwidth(X, quantile=params[\"quantile\"])\n",
    "\n",
    "# connectivity matrix for structured Ward\n",
    "connectivity = kneighbors_graph(\n",
    "    X, n_neighbors=params[\"n_neighbors\"], include_self=False\n",
    ")\n",
    "# make connectivity symmetric\n",
    "connectivity = 0.5 * (connectivity + connectivity.T)\n",
    "\n",
    "# ============\n",
    "# Create cluster objects\n",
    "# ============\n",
    "ms = cluster.MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "two_means = cluster.MiniBatchKMeans(n_clusters=params[\"n_clusters\"])\n",
    "ward = cluster.AgglomerativeClustering(\n",
    "    n_clusters=params[\"n_clusters\"], linkage=\"ward\", connectivity=connectivity\n",
    ")\n",
    "spectral = cluster.SpectralClustering(\n",
    "    n_clusters=params[\"n_clusters\"],\n",
    "    eigen_solver=\"arpack\",\n",
    "    affinity=\"nearest_neighbors\",\n",
    ")\n",
    "dbscan = cluster.DBSCAN(eps=params[\"eps\"])\n",
    "optics = cluster.OPTICS(\n",
    "    min_samples=params[\"min_samples\"],\n",
    "    xi=params[\"xi\"],\n",
    "    min_cluster_size=params[\"min_cluster_size\"],\n",
    ")\n",
    "affinity_propagation = cluster.AffinityPropagation(\n",
    "    damping=params[\"damping\"], preference=params[\"preference\"], random_state=0\n",
    ")\n",
    "average_linkage = cluster.AgglomerativeClustering(\n",
    "    linkage=\"average\",\n",
    "    affinity=\"cityblock\",\n",
    "    n_clusters=params[\"n_clusters\"],\n",
    "    connectivity=connectivity,\n",
    ")\n",
    "birch = cluster.Birch(n_clusters=params[\"n_clusters\"])\n",
    "gmm = mixture.GaussianMixture(\n",
    "    n_components=params[\"n_clusters\"], covariance_type=\"full\"\n",
    ")\n",
    "\n",
    "clustering_algorithms = (\n",
    "    (\"MiniBatch\\nKMeans\", two_means),\n",
    "    (\"Affinity\\nPropagation\", affinity_propagation),\n",
    "    (\"MeanShift\", ms),\n",
    "    (\"Spectral\\nClustering\", spectral),\n",
    "    (\"Ward\", ward),\n",
    "    (\"Agglomerative\\nClustering\", average_linkage),\n",
    "    (\"DBSCAN\", dbscan),\n",
    "    (\"OPTICS\", optics),\n",
    "    (\"BIRCH\", birch),\n",
    "    (\"Gaussian\\nMixture\", gmm),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "from itertools import cycle, islice\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.subplots_adjust(\n",
    "#     left=0.02, right=0.98, bottom=0.001, top=0.95, wspace=0.05, hspace=0.5\n",
    "# )\n",
    "\n",
    "plot_num = 1\n",
    "for name, algorithm in clustering_algorithms:\n",
    "    t0 = time.time()\n",
    "\n",
    "    # catch warnings related to kneighbors_graph\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\n",
    "            \"ignore\",\n",
    "            message=\"the number of connected components of the \"\n",
    "            + \"connectivity matrix is [0-9]{1,2}\"\n",
    "            + \" > 1. Completing it to avoid stopping the tree early.\",\n",
    "            category=UserWarning,\n",
    "        )\n",
    "        warnings.filterwarnings(\n",
    "            \"ignore\",\n",
    "            message=\"Graph is not fully connected, spectral embedding\"\n",
    "            + \" may not work as expected.\",\n",
    "            category=UserWarning,\n",
    "        )\n",
    "        algorithm.fit(X)\n",
    "\n",
    "    t1 = time.time()\n",
    "    if hasattr(algorithm, \"labels_\"):\n",
    "        labels = algorithm.labels_.astype(int)\n",
    "    else:\n",
    "        labels = algorithm.predict(X)\n",
    "\n",
    "    colors = np.array(\n",
    "        list(\n",
    "            islice(\n",
    "                cycle(\n",
    "                    [\n",
    "                        \"#377eb8\",\n",
    "                        \"#ff7f00\",\n",
    "                        \"#4daf4a\",\n",
    "                        \"#f781bf\",\n",
    "                        \"#a65628\",\n",
    "                        \"#984ea3\",\n",
    "                        \"#999999\",\n",
    "                        \"#e41a1c\",\n",
    "                        \"#dede00\",\n",
    "                    ]\n",
    "                ),\n",
    "                int(max(labels) + 1),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    # add black color for outliers (if any)\n",
    "    colors = np.append(colors, [\"#000000\"])\n",
    "\n",
    "    # plt.subplot(4, 3, plot_num)\n",
    "    # plt.title(name, size=10)\n",
    "    # plt.scatter(X[:, 0], X[:, -1], s=10, color=colors[labels])\n",
    "\n",
    "    # plt.xlim(-0.5, 1.5)\n",
    "    # plt.ylim(0, 1.5)\n",
    "    # plt.xticks(())\n",
    "    # plt.yticks(())\n",
    "    \n",
    "    plot_num += 1\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bc6412d3a16fac449111427037f95615ac4f9eb0e21171480bd5fd4cd4869803"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('video2carla')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
